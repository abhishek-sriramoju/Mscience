{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afcdb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import smtplib \n",
    "from pretty_html_table import build_table\n",
    "from datetime import datetime\n",
    "from email.mime.text import MIMEText\n",
    "from email import encoders\n",
    "from email.message import Message\n",
    "from email.mime.audio import MIMEAudio\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.header import Header\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de48cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"C:/Users/abhishek.sriramoju_s/Desktop/keys.txt\"  #File path\n",
    "try:\n",
    "    with open(file_path, 'r') as file:  #Opening the file that contains credentials\n",
    "        content = file.read()  #Reading the file\n",
    "except FileNotFoundError:  \n",
    "    print(f\"File not found at {file_path}\")\n",
    "    content = \"\"\n",
    "    \n",
    "aws_access_key = None  \n",
    "aws_secret_key = None\n",
    "service_name = None\n",
    "region_name = None\n",
    "\n",
    "lines = content.split('\\n') #Spliting the string on the basis of next line\n",
    "for line in lines:\n",
    "    if line.startswith(\"service_name\"):    #Getting the Service Name\n",
    "        service_name = line.split('=')[1].strip()\n",
    "    elif line.startswith(\"region_name\"):   #Getting the Region Name\n",
    "        region_name = line.split('=')[1].strip()\n",
    "    elif line.startswith(\"AWS_ACCESS_KEY_ID\"): #Getting the Access key\n",
    "        aws_access_key = line.split('=')[1].strip()\n",
    "    elif line.startswith(\"AWS_SECRET_ACCESS_KEY\"): #Getting the Secret key\n",
    "        aws_secret_key = line.split('=')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d71d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.ServiceResource()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connecting to amazon s3 bucket \n",
    "resource = boto3.resource(service_name = service_name, #Service Name\n",
    "                    region_name = region_name,   #Region\n",
    "                    aws_access_key_id = aws_access_key, #Access key\n",
    "                    aws_secret_access_key = aws_secret_key) #Secrect key\n",
    "resource               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fb3e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'underarmour1'  #Bucket Name\n",
    "categories_bucket = resource.Bucket(bucket_name) #Getting Bucket object\n",
    "categories_files = categories_bucket.objects.filter(Prefix='categories/')  #Getting the objects of category file\n",
    "category_dates = []  \n",
    "for obj in categories_files :  #Iterating on category files\n",
    "    name = obj.key  #Category file name\n",
    "    if name.endswith('.parquet') :  #Checking the condition weather the file is parquet or not\n",
    "        values = name.split('_')   #Splitting the file names\n",
    "        values = values[0].split('/')[1]  #Will get the date in yyyy.mm.dd\n",
    "        date = list(map(int, values.split('.'))) \n",
    "        category_dates.append((name, datetime(date[0], date[1], date[2]))) #Appending datet and file name in category_dates\n",
    "category_dates.sort(key = lambda x: x[1],reverse = True) #Sorting the list on the basis of date\n",
    "\n",
    "\n",
    "buffer = io.BytesIO()  #Creating an buffer\n",
    "object = resource.Object(bucket_name,category_dates[0][0]) #The Latest File\n",
    "object.download_fileobj(buffer) \n",
    "category_file_2 = pd.read_parquet(buffer) #Reading the parquet file\n",
    "\n",
    "buffer = io.BytesIO()\n",
    "object = resource.Object(bucket_name,category_dates[1][0])\n",
    "object.download_fileobj(buffer)\n",
    "\n",
    "category_file_1 = pd.read_parquet(buffer)\n",
    "\n",
    "# buffer = io.BytesIO()\n",
    "# object = resource.Object(bucket_name,category_dates[2][0])\n",
    "# object.download_fileobj(buffer)\n",
    "\n",
    "# category_file_0 = pd.read_parquet(buffer)\n",
    "# category_file_0\n",
    "\n",
    "\n",
    "\n",
    "product_files = categories_bucket.objects.filter(Prefix='products/')  #Getting the objects of category file\n",
    "product_dates = []  \n",
    "for obj in product_files :  #Iterating on category files\n",
    "    name = obj.key  #Category file name\n",
    "    if name.endswith('.parquet') :  #Checking the condition weather the file is parquet or not\n",
    "        values = name.split('_')   #Splitting the file names\n",
    "        values = values[0].split('/')[1]  #Will get the date in yyyy.mm.dd\n",
    "        date = list(map(int, values.split('.'))) \n",
    "        product_dates.append((name, datetime(date[0], date[1], date[2]))) #Appending datet and file name in category_dates\n",
    "product_dates.sort(key = lambda x: x[1],reverse = True) #Sorting the list on the basis of date\n",
    "\n",
    "\n",
    "buffer = io.BytesIO()  #Creating an buffer\n",
    "object = resource.Object(bucket_name,product_dates[0][0]) #The Latest File\n",
    "object.download_fileobj(buffer) \n",
    "product_file_2 = pd.read_parquet(buffer) #Reading the parquet file\n",
    "\n",
    "\n",
    "buffer = io.BytesIO()  #Creating an buffer\n",
    "object = resource.Object(bucket_name,product_dates[1][0])\n",
    "object.download_fileobj(buffer)\n",
    "\n",
    "product_file_1 = pd.read_parquet(buffer) #Reading the previous product parquet file\n",
    "\n",
    "\n",
    "# buffer = io.BytesIO()\n",
    "# object = resource.Object(bucket_name,product_dates[2][0])\n",
    "# object.download_fileobj(buffer)\n",
    "\n",
    "# product_file_0 = pd.read_parquet(buffer)\n",
    "# product_file_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf381f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent_name</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Specific_column</th>\n",
       "      <th>Description</th>\n",
       "      <th>Missing_categories</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Agent_name, Issue, Specific_column, Description, Missing_categories, URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Agent_name': [],\n",
    "    'Issue': [],\n",
    "    'Specific_column': [],\n",
    "    'Description': [],\n",
    "    'Missing_categories': [],\n",
    "    'URL': []\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3084c81",
   "metadata": {},
   "source": [
    "##### Run ID and Run Date for product file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e934d414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_freq_product_1 = product_file_1[\"RunID\"][0]  #Getting Run ID of previous file\n",
    "run_date_product_1 = product_file_1[\"RunDate\"][0] #Getting Run Date of previous file\n",
    "\n",
    "run_freq_product_2 = product_file_2[\"RunID\"][0]  #Latest File\n",
    "run_date_product_2 = product_file_2[\"RunDate\"][0] #Getting Run Date of Latest file\n",
    "run_freq_product_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdafaa",
   "metadata": {},
   "source": [
    "##### Run ID and Run Date for Category file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73c615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_freq_category_1 = category_file_1[\"RunID\"][0]  #Getting Run ID of previous file\n",
    "run_date_category_1 = category_file_1[\"RunDate\"][0] #Getting Run Date of previous file\n",
    "\n",
    "run_freq_category_2 = category_file_2[\"RunID\"][0]  #Latest File\n",
    "run_date_category_2 = category_file_2[\"RunDate\"][0] #Getting Run Date of Latest file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641cb1d",
   "metadata": {},
   "source": [
    "##### Check for the incremented run date & run id for product file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a71634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIncrement(latest,previous) : #Checking the latest file has greater value or not.\n",
    "    if(latest < previous) : #Checking the condition weather latest data is greater than previous or not\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316cf1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Id is in increasing order\n"
     ]
    }
   ],
   "source": [
    "if(checkIncrement(run_freq_product_2,run_freq_product_1)): #Calling the checkIncrement function and checking weather the latest freq greather than the previous file\n",
    "    print(\"The Latest run id less than the previous run id\")\n",
    "    specific_column = product_file_2.columns[product_file_2.columns == 'RunID'][0]\n",
    "    description = \"Previous RunId :\" + str(run_freq_product_1) + \"Latest RunId :\" + str(run_freq_product_2)\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Increment', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[0])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"Run Id is in increasing order\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3380e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run date is in increasing order\n"
     ]
    }
   ],
   "source": [
    "if(checkIncrement(run_date_product_2,run_date_product_1)): #Calling the checkIncrement function and checking weather the latest Runid greather than the previous file\n",
    "    print(\"The Latest Run Date less than the previous run id\")\n",
    "    specific_column = product_file_2.columns[product_file_2.columns == 'RunDate'][0]\n",
    "    description = \"Previous RunDate :\" + str(run_date_product_1) + \"Latest RunDate :\" + str(run_date_product_2)\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Increment', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[1])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"Run date is in increasing order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e07eecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunDate</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>SKU</th>\n",
       "      <th>UPC</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Price</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>RunID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-04 05:58:26</td>\n",
       "      <td>Men-Training</td>\n",
       "      <td>1361588</td>\n",
       "      <td></td>\n",
       "      <td>1361588</td>\n",
       "      <td>Men's HeatGear® ¾ Leggings</td>\n",
       "      <td>26.9700</td>\n",
       "      <td>None</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-04 07:13:11</td>\n",
       "      <td>Kids-Boys-Pants &amp; Leggings</td>\n",
       "      <td>5112715</td>\n",
       "      <td></td>\n",
       "      <td>5112715</td>\n",
       "      <td>Little Boys' UA Halftone Reaper Pieced Joggers</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>28.9700</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-04 07:13:11</td>\n",
       "      <td>Shoes-Featured-New Arrivals</td>\n",
       "      <td>3026704</td>\n",
       "      <td></td>\n",
       "      <td>3026704</td>\n",
       "      <td>Boys' Pre-School UA Flash Running Shoes</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-04 07:13:11</td>\n",
       "      <td>Kids-Running &amp; Training</td>\n",
       "      <td>1363284</td>\n",
       "      <td></td>\n",
       "      <td>1363284</td>\n",
       "      <td>Boys' UA Tech™ 2.0 Short Sleeve</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>14.9900</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-04 06:39:21</td>\n",
       "      <td>Kids-Featured-Best Sellers</td>\n",
       "      <td>1362489</td>\n",
       "      <td></td>\n",
       "      <td>1362489</td>\n",
       "      <td>Boys' UA Match Play Shorts</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>40.9700</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              RunDate                   CategoryId      SKU UPC ProductId  \\\n",
       "0 2023-10-04 05:58:26                 Men-Training  1361588       1361588   \n",
       "1 2023-10-04 07:13:11   Kids-Boys-Pants & Leggings  5112715       5112715   \n",
       "2 2023-10-04 07:13:11  Shoes-Featured-New Arrivals  3026704       3026704   \n",
       "3 2023-10-04 07:13:11      Kids-Running & Training  1363284       1363284   \n",
       "4 2023-10-04 06:39:21   Kids-Featured-Best Sellers  1362489       1362489   \n",
       "\n",
       "                                      ProductName    Price SalePrice  RunID  \n",
       "0                      Men's HeatGear® ¾ Leggings  26.9700      None   1893  \n",
       "1  Little Boys' UA Halftone Reaper Pieced Joggers  32.0000   28.9700   1893  \n",
       "2         Boys' Pre-School UA Flash Running Shoes  45.0000      None   1893  \n",
       "3                 Boys' UA Tech™ 2.0 Short Sleeve  20.0000   14.9900   1893  \n",
       "4                      Boys' UA Match Play Shorts  45.0000   40.9700   1893  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_file_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af87183",
   "metadata": {},
   "source": [
    "###### In Category file, The categories should be matched with product file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a81057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Categories in Category File is not matching with product file\n"
     ]
    }
   ],
   "source": [
    "category_data = category_file_2[category_file_2['lvl4'] == \"\"] #Getting the rows in which the lvl4 and lvl5 are empty\n",
    "category_data = category_file_1[category_file_1['lvl3'] != \"\"]\n",
    "category_data = category_file_1[category_file_1['lvl2'] != \"\"]\n",
    "categories = category_data['CategoryName'].unique()  #Making the CategoryName Unique in category file\n",
    "products = product_file_2[\"CategoryId\"].unique()     #Making the CategoryId Unique in product file\n",
    "pattern = r'-(?![^(]*\\))' \n",
    "\n",
    "products = np.array([re.split(pattern, item)[-1] for item in products]) #Getting the last category from product file\n",
    "\n",
    "result = np.array([any(element in keyword for keyword in categories) for element in products]) #Checking weather the last category in product file matching with categories in categories file\n",
    "if result.all(): #Checking weather all the values are True or not\n",
    "    print(\"The Categories in Category File is matching with product file\")\n",
    "    print(products)\n",
    "else :\n",
    "    category_data = category_file_1[category_file_1['lvl4'] == \"\"] #Getting the rows in which the lvl4 and lvl5 are empty\n",
    "    category_data = category_file_1[category_file_1['lvl3'] != \"\"]\n",
    "    category_data = category_file_1[category_file_1['lvl2'] != \"\"]\n",
    "    categories = category_data['CategoryName'].unique()  #Making the CategoryName Unique in category file\n",
    "    products = product_file_2[\"CategoryId\"].unique()     #Making the CategoryId Unique in product file\n",
    "    pattern = r'-(?![^(]*\\))' \n",
    "    products = np.array([re.split(pattern, item)[-1] for item in products]) #Getting the last category from product file\n",
    "\n",
    "    result = np.array([any(element in keyword for keyword in categories) for element in products]) #Checking weather the last category in product file matching with categories in categories file\n",
    "    \n",
    "    if result.all(): #Checking weather all the values are True or not\n",
    "        print(\"The Categories in Category File is matching with product file\")\n",
    "    else :\n",
    "        print(\"The Categories in Category File is not matching with product file\")\n",
    "        index = np.where(result == False)\n",
    "        missing_categoies = str(products[index])\n",
    "        specific_column = product_file_2.columns[product_file_2.columns == 'CategoryId'][0]\n",
    "        description = \"The Categories in product file is missing in category file\"\n",
    "        new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Category Missing', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": missing_categoies,'URL': ''},index=[2])\n",
    "        df = pd.concat([df, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b44e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNull(data):  #Function for checking the null values in particular column of dataframe\n",
    "    if(data.isnull().sum() or data.all() == \"None\"):  \n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701e1d1",
   "metadata": {},
   "source": [
    "##### Checking in Category file weather the particular columns contains null or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee2b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryId does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(product_file_2['CategoryId'])):  #Passing Category Id column in product file to check weather it contains null entries or not\n",
    "    print(\"CategoryId contains Null values\")\n",
    "    specific_column = product_file_2.columns[product_file_2.columns == 'CategoryId'][0]\n",
    "    description = \"Category Id's is missing in product file\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[3])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"CategoryId does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f051d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(product_file_2['SKU'])):  #Passing SKU column in product file to check weather it contains null entries or not\n",
    "    print(\"SKU contains Null values\")\n",
    "    specific_column = product_file_2.columns[product_file_2.columns == 'SKU'][0]\n",
    "    description = \"SKU values are missing in product file\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[4])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"SKU does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7a78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductName does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(product_file_2['ProductName'])):  #Passing ProductName column in product file to check weather it contains null entries or not\n",
    "    print(\"ProductName contains Null values\")\n",
    "    specific_column = product_file_2.columns[product_file_2.columns == 'ProductName'][0]\n",
    "    description = \"ProductName values are missing in product file\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[5])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"ProductName does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f025b73b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data count is fine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22184.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_file_size = (product_file_2.shape[0] + product_file_1.shape[0])/2 #Average file count of latest 3 product files\n",
    "percentage_count = ((average_file_size - product_file_2.shape[0])/(average_file_size))*100 #Getting the percentage count\n",
    "if percentage_count > 5 or percentage_count < -5 :\n",
    "    print(\"There is an issue with the count\")\n",
    "    description = \"Previous Data Count:\" + str(product_file_1.shape[0]) + \"Latest Data count\" + str(product_file_2.shape[0]) + \"Percentage count:\" + str(percentage_count)\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Data Count', 'Specific_column': '', 'Description': description ,\"Missing_categories\": '','URL': ''},index=[6])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else :\n",
    "    print(\"Data count is fine\")\n",
    "    \n",
    "average_file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6c38eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates were found\n"
     ]
    }
   ],
   "source": [
    "#Getting the duplicate count on the basis of unique id\n",
    "duplicates = product_file_2[product_file_2.duplicated(subset=['CategoryId', 'ProductId'])] \n",
    "if(duplicates.shape[0] > 0) :\n",
    "    print(duplicates.shape[0],\"duplicates were found\")\n",
    "    specific_column = product_file_2.columns[product_file_2.columns == 'ProductId'][0]\n",
    "    description = str(duplicates['ProductId']) + \"Found duplicates\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Duplicates', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[7])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else :\n",
    "    print(\"No duplicates were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "960da441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count is 22372\n"
     ]
    }
   ],
   "source": [
    "#total count on the basis of unique id\n",
    "total_count = (product_file_2['CategoryId'].astype(str) + '-' + product_file_2['ProductId'].astype(str))\n",
    "print(\"total count is\",total_count.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be68f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunID does not contain null values\n"
     ]
    }
   ],
   "source": [
    "#Passing RunID column in Category file to check weather it contains null entries or not\n",
    "if(checkNull(category_file_2['RunID'])):  \n",
    "    print(\"RunID contains Null values\")\n",
    "    specific_column = category_file_2.columns[category_file_2.columns == 'RunID'][0]\n",
    "    description = \"RunID contains null vales\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[8])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"RunID does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67af954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunDate does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(category_file_2['RunDate'])):  #Passing RunDate column in Category file to check weather it contains null entries or not\n",
    "    print(\"RunDate contains Null values\")\n",
    "    specific_column = category_file_2.columns[category_file_2.columns == 'RunDate'][0]\n",
    "    description = \"RunDate contains null vales\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[9])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"RunDate does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca026eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(category_file_2['Url'])):  #Passing Url column in Category file to check weather it contains null entries or not\n",
    "    print(\"Url contains Null values\")\n",
    "    specific_column = category_file_2.columns[category_file_2.columns == 'Url'][0]\n",
    "    description = \"Url contains null vales\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[10])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"Url does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11309b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryID does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(category_file_2['CategoryID'])):  #Passing CategoryID column in Category file to check weather it contains null entries or not\n",
    "    print(\"CategoryID contains Null values\")\n",
    "    specific_column = category_file_2.columns[category_file_2.columns == 'CategoryID'][0]\n",
    "    description = \"CategoryID contains null vales\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[11])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"CategoryID does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a5b8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryLevel does not contain null values\n"
     ]
    }
   ],
   "source": [
    "if(checkNull(category_file_2['CategoryLevel'])):  #Passing CategoryLevel column in Category file to check weather it contains null entries or not\n",
    "    print(\"CategoryLevel contains Null values\")\n",
    "    specific_column = category_file_2.columns[category_file_2.columns == 'CategoryLevel'][0]\n",
    "    description = \"CategoryLevel contains null vales\"\n",
    "    new_data = pd.DataFrame({'Agent_name': 'underarmour', 'Issue': 'Check Null', 'Specific_column': specific_column, 'Description': description ,\"Missing_categories\": '','URL': ''},index=[12])\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "else:\n",
    "    print(\"CategoryLevel does not contain null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b24e653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunDate</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>SKU</th>\n",
       "      <th>UPC</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Price</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>RunID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-05 05:27:37</td>\n",
       "      <td>New &amp; Featured-Featured-UA Fleece Shop</td>\n",
       "      <td>1377446</td>\n",
       "      <td></td>\n",
       "      <td>1377446</td>\n",
       "      <td>Women's Project Rock Heavyweight Terry Full-Zip</td>\n",
       "      <td>95.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-05 05:58:16</td>\n",
       "      <td>Men-Shoes</td>\n",
       "      <td>3022707</td>\n",
       "      <td></td>\n",
       "      <td>3022707</td>\n",
       "      <td>Men's UA Ignite III Sandals</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>31.9700</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-05 07:15:01</td>\n",
       "      <td>Kids-Running &amp; Training</td>\n",
       "      <td>5119951</td>\n",
       "      <td></td>\n",
       "      <td>5119951</td>\n",
       "      <td>Little Boys' UA Fader Block Logo Long Sleeve &amp;...</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-05 08:13:03</td>\n",
       "      <td>Outlet-Girls-Shorts</td>\n",
       "      <td>1377024</td>\n",
       "      <td></td>\n",
       "      <td>1377024</td>\n",
       "      <td>Girls' UA Play Up Big Logo Graphic Shorts</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>18.9700</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-05 05:27:37</td>\n",
       "      <td>New &amp; Featured-Featured-UA Fleece Shop</td>\n",
       "      <td>5120630</td>\n",
       "      <td></td>\n",
       "      <td>5120630</td>\n",
       "      <td>Men's UA Tech™ Terry Gameday Collegiate ¼ Zip</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22367</th>\n",
       "      <td>2023-10-05 08:13:03</td>\n",
       "      <td>Outlet-Boys-Shirts &amp; Tops</td>\n",
       "      <td>1378939</td>\n",
       "      <td></td>\n",
       "      <td>1378939</td>\n",
       "      <td>Kids' UA Pride Short Sleeve</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>24.9700</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22368</th>\n",
       "      <td>2023-10-05 05:58:16</td>\n",
       "      <td>Men-UA HeatGear®: Keeps You Cool</td>\n",
       "      <td>1376427</td>\n",
       "      <td></td>\n",
       "      <td>1376427</td>\n",
       "      <td>Men's UA Gameday Armour Pro 5-Pad Top</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22369</th>\n",
       "      <td>2023-10-05 05:27:37</td>\n",
       "      <td>New &amp; Featured-Featured-Sportstyle</td>\n",
       "      <td>1373101</td>\n",
       "      <td></td>\n",
       "      <td>1373101</td>\n",
       "      <td>Women's UA Halftime Cuff Beanie</td>\n",
       "      <td>20.9700</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22370</th>\n",
       "      <td>2023-10-05 07:15:01</td>\n",
       "      <td>Kids-Big Kids (8-20)</td>\n",
       "      <td>1364980</td>\n",
       "      <td></td>\n",
       "      <td>1364980</td>\n",
       "      <td>Boys' UA Command Warm-Up Pants</td>\n",
       "      <td>54.9700</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22371</th>\n",
       "      <td>2023-10-05 05:27:37</td>\n",
       "      <td>New &amp; Featured-Featured-Color Spotlight: Purple</td>\n",
       "      <td>1380773</td>\n",
       "      <td></td>\n",
       "      <td>1380773</td>\n",
       "      <td>Women's UA Meridian Mock Long Sleeve</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22372 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RunDate                                       CategoryId  \\\n",
       "0     2023-10-05 05:27:37           New & Featured-Featured-UA Fleece Shop   \n",
       "1     2023-10-05 05:58:16                                        Men-Shoes   \n",
       "2     2023-10-05 07:15:01                          Kids-Running & Training   \n",
       "3     2023-10-05 08:13:03                              Outlet-Girls-Shorts   \n",
       "4     2023-10-05 05:27:37           New & Featured-Featured-UA Fleece Shop   \n",
       "...                   ...                                              ...   \n",
       "22367 2023-10-05 08:13:03                        Outlet-Boys-Shirts & Tops   \n",
       "22368 2023-10-05 05:58:16                 Men-UA HeatGear®: Keeps You Cool   \n",
       "22369 2023-10-05 05:27:37               New & Featured-Featured-Sportstyle   \n",
       "22370 2023-10-05 07:15:01                             Kids-Big Kids (8-20)   \n",
       "22371 2023-10-05 05:27:37  New & Featured-Featured-Color Spotlight: Purple   \n",
       "\n",
       "           SKU UPC ProductId  \\\n",
       "0      1377446       1377446   \n",
       "1      3022707       3022707   \n",
       "2      5119951       5119951   \n",
       "3      1377024       1377024   \n",
       "4      5120630       5120630   \n",
       "...        ...  ..       ...   \n",
       "22367  1378939       1378939   \n",
       "22368  1376427       1376427   \n",
       "22369  1373101       1373101   \n",
       "22370  1364980       1364980   \n",
       "22371  1380773       1380773   \n",
       "\n",
       "                                             ProductName    Price SalePrice  \\\n",
       "0        Women's Project Rock Heavyweight Terry Full-Zip  95.0000      None   \n",
       "1                            Men's UA Ignite III Sandals  35.0000   31.9700   \n",
       "2      Little Boys' UA Fader Block Logo Long Sleeve &...  40.0000      None   \n",
       "3              Girls' UA Play Up Big Logo Graphic Shorts  25.0000   18.9700   \n",
       "4          Men's UA Tech™ Terry Gameday Collegiate ¼ Zip  75.0000      None   \n",
       "...                                                  ...      ...       ...   \n",
       "22367                        Kids' UA Pride Short Sleeve  30.0000   24.9700   \n",
       "22368              Men's UA Gameday Armour Pro 5-Pad Top  75.0000      None   \n",
       "22369                    Women's UA Halftime Cuff Beanie  20.9700      None   \n",
       "22370                     Boys' UA Command Warm-Up Pants  54.9700      None   \n",
       "22371               Women's UA Meridian Mock Long Sleeve  75.0000      None   \n",
       "\n",
       "       RunID  \n",
       "0       1894  \n",
       "1       1894  \n",
       "2       1894  \n",
       "3       1894  \n",
       "4       1894  \n",
       "...      ...  \n",
       "22367   1894  \n",
       "22368   1894  \n",
       "22369   1894  \n",
       "22370   1894  \n",
       "22371   1894  \n",
       "\n",
       "[22372 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_file = product_file_2[product_file_2['SalePrice'] != product_file_2['SalePrice'].isnull()]\n",
    "product_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ee4178c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunDate</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>SKU</th>\n",
       "      <th>UPC</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Price</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>RunID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-05 05:27:37</td>\n",
       "      <td>New &amp; Featured-Featured-UA Fleece Shop</td>\n",
       "      <td>1377446</td>\n",
       "      <td></td>\n",
       "      <td>1377446</td>\n",
       "      <td>Women's Project Rock Heavyweight Terry Full-Zip</td>\n",
       "      <td>95.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-05 05:58:16</td>\n",
       "      <td>Men-Shoes</td>\n",
       "      <td>3022707</td>\n",
       "      <td></td>\n",
       "      <td>3022707</td>\n",
       "      <td>Men's UA Ignite III Sandals</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>31.9700</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-05 07:15:01</td>\n",
       "      <td>Kids-Running &amp; Training</td>\n",
       "      <td>5119951</td>\n",
       "      <td></td>\n",
       "      <td>5119951</td>\n",
       "      <td>Little Boys' UA Fader Block Logo Long Sleeve &amp;...</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              RunDate                              CategoryId      SKU UPC  \\\n",
       "0 2023-10-05 05:27:37  New & Featured-Featured-UA Fleece Shop  1377446       \n",
       "1 2023-10-05 05:58:16                               Men-Shoes  3022707       \n",
       "2 2023-10-05 07:15:01                 Kids-Running & Training  5119951       \n",
       "\n",
       "  ProductId                                        ProductName    Price  \\\n",
       "0   1377446    Women's Project Rock Heavyweight Terry Full-Zip  95.0000   \n",
       "1   3022707                        Men's UA Ignite III Sandals  35.0000   \n",
       "2   5119951  Little Boys' UA Fader Block Logo Long Sleeve &...  40.0000   \n",
       "\n",
       "  SalePrice  RunID  \n",
       "0      None   1894  \n",
       "1   31.9700   1894  \n",
       "2      None   1894  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_file_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25e19292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kids-Running & Training                992\n",
       "Kids-Big Kids (8-20)                   795\n",
       "Men-Training                           777\n",
       "Women-Training                         721\n",
       "Men-Shirts & Tops                      638\n",
       "                                      ... \n",
       "New & Featured-Gift Guide-Gift Card      2\n",
       "Men-UA SlipSpeed™                        2\n",
       "Women-UA SlipSpeed™                      2\n",
       "Shoes-Featured-UA SlipSpeed™             2\n",
       "Outlet-Men-Underwear                     1\n",
       "Name: CategoryId, Length: 248, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_id_groupby_1 = product_file_2[\"CategoryId\"].value_counts()\n",
    "category_id_groupby_1 = product_file_1[\"CategoryId\"].value_counts()\n",
    "category_id_groupby_1\n",
    "# category_id_groupby_1.values == category_id_groupby_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d99a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "Previous_data = product_file_1.shape[0]\n",
    "Current_data = product_file_2.shape[0]\n",
    "Detail_count_difference = Current_data - Previous_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca0a0ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully.\n"
     ]
    }
   ],
   "source": [
    "# Email configuration\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "smtp_port = 587\n",
    "sender_email = \"sriramojuabhishek264@gmail.com\"\n",
    "sender_password = \"pzwr kphf sshp sopc\"\n",
    "recipient_email = \"abhishek.sriramoju@sequentum.com\"\n",
    "\n",
    "\n",
    "underarmour_report = [[Previous_data,Current_data,Detail_count_difference, percentage_count]]\n",
    "# # underarmour_report = []\n",
    "\n",
    "\n",
    "table_header1 = [\"Previous_Day_Count\",\n",
    "                     \"Today_Count\",\n",
    "                     \"Count_Difference\",\n",
    "                     \"Percentage_Difference(%)\"\n",
    "                     ]\n",
    "\n",
    "# # data into a Pandas DataFrame\n",
    "extracted_data = pd.DataFrame(underarmour_report, columns=table_header1)\n",
    "\n",
    "#styled_extracted_data = extracted_data.style.hide_index()\n",
    "\n",
    "#styled_extracted_data_new = extracted_data.format({'Percentage_Difference(%)': '{:.2f}%'})\n",
    "\n",
    "issue_table = build_table(df, \"blue_light\")\n",
    "\n",
    "issue_table_analysis = build_table(extracted_data, \"blue_light\")\n",
    "\n",
    "# append in email_body and return it\n",
    "email_body = \"<strong><h3>\\n\\nPlease check the below table for data issues.</h3></strong>\\n\"\n",
    "email_body += issue_table\n",
    "email_body += issue_table_analysis\n",
    "\n",
    "# Create the email message\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = sender_email\n",
    "msg['To'] = recipient_email\n",
    "msg['Subject'] = 'Table in Email'\n",
    "\n",
    "# Attach the HTML message to the email\n",
    "#msg.attach(MIMEText(table_html, 'html'))\n",
    "\n",
    "attachment = MIMEText(df.to_csv(index=False), 'csv')\n",
    "analysis_attachment = MIMEText(extracted_data.to_csv(index=False), 'csv')\n",
    "\n",
    "\n",
    "attachment.add_header('Content-Disposition', 'attachment', filename='underarmour_report.csv')\n",
    "msg.attach(attachment)\n",
    "msg.attach(MIMEText(email_body,'html'))\n",
    "\n",
    "\n",
    "# Connect to the SMTP server and send the email\n",
    "with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "    server.starttls()\n",
    "    server.login(sender_email, sender_password)\n",
    "    server.sendmail(sender_email, recipient_email, msg.as_string())\n",
    "\n",
    "print(\"Email sent successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "091f2125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[21997, 22372, 375, -0.8451847010299985]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "underarmour_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96040646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
